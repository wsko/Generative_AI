{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outline**\n",
    "\n",
    "\n",
    "- Overview of NLP: Understanding Language as Data\n",
    "- Language Generation Tasks\n",
    "  - Text Completion\n",
    "  - Text Generation\n",
    "  - Dialogue Systems\n",
    "  - Story Generation\n",
    "- Pre-trained Language Models \n",
    "  - Pre-trained Language Models (e.g., GPT, BERT)\n",
    "  - Fine-tuning for Language Generation Tasks\n",
    "- Using Hugging Face's Transformers Library for LLMs\n",
    "  - Adapting Pre-trained Models for Specific NLP Tasks\n",
    "- Capstone Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Our will focus on using Neural Networks to handle tasks related to **Natural Language Processing (NLP)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Natural Language Processing (NLP)**\n",
    "\n",
    "- Natural Language Processing (NLP) is a branch of artificial intelligence (AI).\n",
    "- It focuses on the interaction between computers and human language.\n",
    "- NLP enables computers to understand, process, and generate human language as data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Why NLP Matters**\n",
    "\n",
    "- NLP has practical applications in various domains:\n",
    "  - Customer service chatbots\n",
    "  - Sentiment analysis of social media data\n",
    "  - Language translation\n",
    "  - Content generation\n",
    "- It bridges the gap between human communication and AI systems.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NLP Tasks**\n",
    "\n",
    "- NLP involves a range of tasks, including:\n",
    "  - Understanding language structure\n",
    "  - Text completion\n",
    "  - Text generation\n",
    "  - Dialogue systems (chatbots)\n",
    "  - Story generation\n",
    "- These tasks have real-world applications and are continuously evolving.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Understanding Language as Data**\n",
    "\n",
    "**Tokenization Example**\n",
    "\n",
    "- Tokenization is the process of splitting text into words or phrases.\n",
    "- It's a fundamental step in NLP.\n",
    "\n",
    "**Named Entity Recognition (NER) Demo**\n",
    "\n",
    "- Visit the [spaCy NER Demo](https://explosion.ai/demos/displacy-ent).\n",
    "- Input a sentence with named entities, e.g., \"Apple Inc. is headquartered in Cupertino, California.\"\n",
    "- Click \"Visualize\" to see entity recognition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Language Generation Tasks**\n",
    "\n",
    "**Text Completion**\n",
    "\n",
    "- Demonstrated by Google Search's auto-suggestion feature.\n",
    "- It suggests the next word or phrase as you type your search query.\n",
    "\n",
    "**Text Generation**\n",
    "\n",
    "- Try the \"GPT-3 Playground\" by OpenAI.\n",
    "- Enter prompts like \"Once upon a time, in a land far, far away...\"\n",
    "- Click \"Create\" to generate creative text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dialogue Systems**\n",
    "\n",
    "**Chatbot Demo (Dialogflow)**\n",
    "\n",
    "- Go to [Dialogflow Console](https://console.cloud.google.com/dialogflow).\n",
    "- Create an agent with intents like \"Greeting.\"\n",
    "- Define responses like \"Hello! How can I assist you today?\"\n",
    "- Test your chatbot in real-time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Story Generation**\n",
    "\n",
    "**Interactive Storytelling (AI Dungeon)**\n",
    "\n",
    "- Visit the [AI Dungeon](https://play.aidungeon.io/) website.\n",
    "- Choose a setting or genre (e.g., \"Fantasy\" or \"Mystery\").\n",
    "- Start a story with a sentence like \"You find yourself in a dark, enchanted forest...\"\n",
    "- AI generates the next part of the story for interactive storytelling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Classification**\n",
    "\n",
    "* Text classification is a common task where text sequences are categorized.\n",
    "    * **Examples**:\n",
    "        * Classifying e-mails into **spam** or **no-spam**.\n",
    "        * Categorizing news articles into **sport**, **business**, **politics**, etc.\n",
    "\n",
    "* In chatbot development, it's crucial to comprehend user intent. This is termed as **intent classification**.\n",
    "    * **Example**:\n",
    "        * User says: \"How's the weather tomorrow?\"\n",
    "        * Bot understands the intent as: **Check Weather**\n",
    "\n",
    "Note: With intent classification, there can often be a multitude of categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sentiment Analysis**\n",
    "\n",
    "* **Sentiment analysis** is typically a regression problem. The aim is to assign a numerical value representing the sentiment (how positive or negative) of a sentence.\n",
    "    * **Example**:\n",
    "        * Sentence: \"I love this product!\"\n",
    "        * Sentiment Score: +0.9 (where +1 is very positive and -1 is very negative)\n",
    "\n",
    "* An advanced form is **aspect-based sentiment analysis** (ABSA). Here, sentiment scores are given to different parts of the sentence.\n",
    "    * **Example**:\n",
    "        * Sentence: \"In this restaurant, I liked the cuisine, but the atmosphere was awful.\"\n",
    "        * Sentiments:\n",
    "            * Cuisine: +0.8\n",
    "            * Atmosphere: -0.9\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Keyword Extraction**\n",
    "\n",
    "* **Keyword extraction** is akin to NER. However, it focuses on automatically extracting words vital to a sentence's meaning, without any prior training on specific entity types.\n",
    "    * **Example**:\n",
    "        * Sentence: \"The Great Barrier Reef is a natural wonder located off the coast of Australia.\"\n",
    "        * Extracted Keywords: **Great Barrier Reef**, **natural wonder**, **coast**, **Australia**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Text Clustering**\n",
    "\n",
    "* **Text clustering** involves grouping similar text sequences or sentences. It can be particularly helpful in contexts like grouping related inquiries in technical support interactions.\n",
    "    * **Example**:\n",
    "        * Tech Support Messages:\n",
    "            * \"My device won't turn on.\"\n",
    "            * \"I can't get my gadget to power up.\"\n",
    "            * \"How do I update my software?\"\n",
    "        * Clustered Results:\n",
    "            * Cluster 1: **Power issues** - \"My device won't turn on.\", \"I can't get my gadget to power up.\"\n",
    "            * Cluster 2: **Software updates** - \"How do I update my software?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **Question Answering**\n",
    "\n",
    "* **Question answering** is about a model's capability to respond to a specific query. Given a text passage and a question, the model identifies the segment of the text containing the answer or, in some cases, generates the answer text.\n",
    "    * **Example**:\n",
    "        * Passage: \"The Eiffel Tower is located in Paris and was completed in 1889.\"\n",
    "        * Question: \"When was the Eiffel Tower completed?\"\n",
    "        * Answer: \"The Eiffel Tower was completed in **1889**.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Text Generation**\n",
    "\n",
    "* **Text Generation** pertains to a model's ability to produce novel text. It's like a classification task predicting the next character or word based on a given *text prompt*.\n",
    "    * **Example**:\n",
    "        * Prompt: \"Once upon a time,\"\n",
    "        * Generated continuation: \"in a land far away, there lived a wise old dragon.\"\n",
    "\n",
    "* Advanced models, like GPT-3, can tackle other NLP tasks such as classification via techniques like [prompt programming](https://towardsdatascience.com/software-3-0-how-prompting-will-change-the-rules-of-the-game-a982fbfe1e0) or [prompt engineering](https://medium.com/swlh/openai-gpt-3-and-prompt-engineering-dcdc2c5fcd29).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Text Summarization**\n",
    "\n",
    "* **Text summarization** is about enabling a computer to \"read\" lengthy text and condense it into a short, coherent summary.\n",
    "    * **Example**:\n",
    "        * Original Text: \"The solar system consists of the Sun and the objects that orbit it. These objects include planets, dwarf planets, moons, and asteroids. The largest planet in the solar system is Jupiter, while Mercury is the smallest.\"\n",
    "        * Summarized Text: \"The solar system includes the Sun, planets, and other celestial objects. Jupiter is the largest planet, and Mercury is the smallest.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Machine Translation and NLP**\n",
    "\n",
    "* **Machine translation** is a blend of understanding text in one language and generating text in another.\n",
    "    * **Traditional Approach**:\n",
    "        1. Use parsers to convert a sentence into a syntax tree.\n",
    "        2. Extract higher-level semantic structures for the sentence's meaning.\n",
    "        3. Generate the translated output based on this meaning and the target language's grammar.\n",
    "    * **Modern Approach**: Use neural networks for more effective results in many NLP tasks.\n",
    "\n",
    "> Traditionally, many NLP tasks were tackled using methods like grammars. However, the paradigm has shifted towards neural network-based solutions in recent years.\n",
    "\n",
    "* **Resources**:\n",
    "    - Classical methods can be found in the [Natural Language Processing Toolkit (NLTK)](https://www.nltk.org).\n",
    "    - The [NLTK Book](https://www.nltk.org/book/) provides an online guide on solving NLP tasks using NLTK.\n",
    "\n",
    "* **Course Approach**:\n",
    "    * We will predominantly focus on Neural Networks for NLP and incorporate NLTK as required.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Neural Networks: From Images to Text**\n",
    "\n",
    "* **Tabular Data & Images**:\n",
    "    - We've explored using neural networks for fixed-size inputs like tabular data and images.\n",
    "    - Images have a predetermined input size.\n",
    "\n",
    "* **Text**:\n",
    "    - Text is a variable-length sequence, making it distinct.\n",
    "    - Textual patterns can be intricate. For instance, the distance between a subject and its negation can vary but should be recognized as a singular pattern.\n",
    "        * **Examples**:\n",
    "            - \"I do not like oranges.\"\n",
    "            - \"I do not like those big colorful tasty oranges.\"\n",
    "\n",
    "* **Solution for Text**:\n",
    "    - Traditional convolutional networks might not capture such complex patterns in text.\n",
    "    - To process language effectively, we introduce new neural architectures:\n",
    "        1. **Recurrent Networks**\n",
    "        2. **Transformers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Representing Text**\n",
    "\n",
    "<img src=\"./images/ascii-character-map.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "\n",
    "- To solve NLP tasks with neural networks, we need text representation as tensors.\n",
    "- Computers use encodings like ASCII or UTF-8 to map text characters to numbers.\n",
    "- Computers lack inherent understanding, and neural networks must learn meaning during training.\n",
    "- Two common approaches for text representation: \n",
    "  - character-level and word-level.\n",
    "- Regardless of approach, text is tokenized, converted to numbers, and fed into the network using one-hot encoding.\n",
    "\n",
    "\n",
    "## **N-Grams**\n",
    "\n",
    "- Precise word meanings depend on context (e.g., \"neural network\" vs. \"fishing network\").\n",
    "- Address context by considering pairs of words or even tri-grams.\n",
    "- This approach, called n-grams, increases dictionary size.\n",
    "- N-grams can also be used with character-level representation.\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## **Bag-of-Words and TF/IDF**\n",
    "\n",
    "\n",
    "<img src=\"images/bow.png\" width=\"90%\"/>\n",
    "\n",
    "\n",
    "- Text classification requires fixed-size vector representation.\n",
    "- Bag of Words (BoW) combines word representations, often using word frequencies.\n",
    "- BoW can indicate text content based on word frequencies.\n",
    "- TF/IDF (Term Frequency-Inverse Document Frequency) reduces the importance of common words.\n",
    "- TF/IDF considers word frequency across the document collection.\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## **Semantics of Text**\n",
    "\n",
    "- Existing approaches cannot fully capture text semantics.\n",
    "- More powerful neural network models are required.\n",
    "- Explore further in attached notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/NLP10.png\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/NLP20.png\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/NLP30.png\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/NLP40.png\" align=\"center\"/>\n",
    "\n",
    "<img src=\"./images/NLP50.png\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import os\n",
    "import collections\n",
    "os.makedirs('./data',exist_ok=True)\n",
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='./data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "list(train_dataset)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because datasets are iterators, if we want to use the data multiple times we need to convert it to list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='./data')\n",
    "train_dataset = list(train_dataset)\n",
    "test_dataset = list(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he', 'said', 'hello', 'i', 'am', 'fine-well']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "tokenizer('He said: hello I am fine-well')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['she', 'said', 'hello', 'i', 'am', 'fantastic']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('SHe said: hello I am fantastic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they', 'said', 'what', 'are', 'you', 'talking', 'about']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('they said: what are you talking about')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = torchtext.vocab.vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using vocabulary, we can easily encode out tokenized string into a set of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size if 95810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[599, 3279, 97, 1220, 329, 225, 7368]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab size if {vocab_size}\")\n",
    "\n",
    "stoi = vocab.get_stoi() # dict to convert tokens to indices\n",
    "\n",
    "def encode(x):\n",
    "    return [stoi[s] for s in tokenizer(x)]\n",
    "\n",
    "encode('I love to play with my words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BoW is a widely used traditional vector representation in text analysis.\n",
    "- Each word is associated with a vector index.\n",
    "- Vector elements store the count of word occurrences in a given document.\n",
    "![Image showing how a bag of words vector representation is represented in memory.](images/bag-of-words-example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 2, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "corpus = [\n",
    "        'I like hot dogs.',\n",
    "        'The dog ran fast.',\n",
    "        'Its hot outside.',\n",
    "    ]\n",
    "vectorizer.fit_transform(corpus)\n",
    "vectorizer.transform(['My dog likes hot dogs on a hot day.']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Word Embeddings**\n",
    "\n",
    "- When training classifiers based on BoW or TF/IDF, we work with high-dimensional one-hot encoded vectors of length `vocab_size`.\n",
    "- One-hot encoding is memory-inefficient and treats words independently, lacking semantic similarity.\n",
    "\n",
    "\n",
    "![Embedding and Semantic Similarity](images/NLP1.webp)\n",
    "\n",
    "- **Embedding** is the idea of representing words as lower-dimensional dense vectors that capture semantic meaning.\n",
    "- It reduces the dimensionality of word vectors.\n",
    "\n",
    "- The embedding layer takes a word as input and produces an output vector of specified `embedding_size`.\n",
    "- Unlike one-hot encoding, it takes a word number as input, avoiding large one-hot-encoded vectors.\n",
    "\n",
    "- Using an embedding layer as the first layer in a classifier network transforms it from a bag-of-words model to an **embedding bag** model.\n",
    "- In this model, words are converted into embeddings, and an aggregate function (e.g., `sum`, `average`, `max`) is applied to these embeddings.\n",
    "\n",
    "![Embedding Classifier Example](images/embedding-classifier-example.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Word Embeddings**\n",
    "\n",
    "- Early NLP models used word embeddings.\n",
    "- Each word mapped to a fixed-size vector.\n",
    "- Word2Vec, GloVe, and FastText were popular methods.\n",
    "\n",
    "\n",
    "- Word2Vec\n",
    "  - Word2Vec is a popular word embedding technique in natural language processing (NLP).\n",
    "  - It transforms words into dense vectors in a continuous vector space.\n",
    "  - Two main approaches: Skip-gram and Continuous Bag of Words (CBOW).\n",
    "  - Word2Vec captures semantic relationships and context between words.\n",
    "  - Used for various NLP tasks, including text classification, sentiment analysis, and recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from gensim) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from gensim) (6.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'learning':\n",
      " [-0.08619688  0.03665738  0.05189884  0.05741938  0.07466918 -0.06167675\n",
      "  0.01105614  0.06047282 -0.0284005  -0.06173522]\n",
      "Words similar to 'processing':\n",
      " [('rocks', 0.3792896866798401), ('capture', 0.27556225657463074)]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Sample sentences for training the Word2Vec model\n",
    "sentences = [\n",
    "    [\"machine\", \"learning\", \"is\", \"awesome\"],\n",
    "    [\"word\", \"embeddings\", \"capture\", \"context\"],\n",
    "    [\"natural\", \"language\", \"processing\", \"rocks\"]\n",
    "]\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=10, window=5, min_count=1, sg=0)\n",
    "\n",
    "# Get the word vector for a specific word\n",
    "word_vector = model.wv['learning']\n",
    "print(\"Vector for 'learning':\\n\", word_vector)\n",
    "\n",
    "# Find similar words to a given word\n",
    "similar_words = model.wv.most_similar('awesome', topn=2)\n",
    "print(\"Words similar to 'processing':\\n\", similar_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Limitations of Word Embeddings**\n",
    "  - Fixed-length vectors don't capture context well.\n",
    "  - Struggle with polysemy (multiple meanings).\n",
    "  - Limited understanding of word relationships.\n",
    "\n",
    "## **Transformers**\n",
    "\n",
    "  - The Transformer architecture revolutionized NLP.\n",
    "  - Introduced self-attention mechanisms.\n",
    "  - Captures context and dependencies effectively.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Timeline\n",
    "\n",
    "\n",
    "![Embedding Classifier Example](images/NLP2.svg)\n",
    "\n",
    "- June 2017\n",
    "  - Introduction of the Transformer architecture\n",
    "\n",
    "- June 2018\n",
    "  - **GPT** (Generative Pretrained Transformer)\n",
    "  - First pretrained Transformer model\n",
    "  - Used for fine-tuning on NLP tasks\n",
    "  - Achieved state-of-the-art results\n",
    "\n",
    "- October 2018\n",
    "  - **BERT** (Bidirectional Encoder Representations from Transformers)\n",
    "  - Large pretrained model\n",
    "  - Designed for better sentence summarization\n",
    "  - More on this in the next chapter!\n",
    "\n",
    "- February 2019\n",
    "  - **GPT-2**\n",
    "  - Improved and larger version of GPT\n",
    "  - Delayed public release due to ethical concerns\n",
    "\n",
    "- October 2019\n",
    "  - **DistilBERT**\n",
    "  - Distilled version of BERT\n",
    "  - 60% faster, 40% lighter in memory\n",
    "  - Still retains 97% of BERT's performance\n",
    "\n",
    "  - **BART and T5**\n",
    "    - Large pretrained models\n",
    "    - Same architecture as the original Transformer\n",
    "\n",
    "- May 2020\n",
    "  - **GPT-3**\n",
    "  - Even bigger than GPT-2\n",
    "  - Performs well on various tasks without fine-tuning\n",
    "  - Known for zero-shot learning\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## **Transformer Model Types**\n",
    "\n",
    "- **GPT-like**\n",
    "  - Also known as auto-regressive Transformer models\n",
    "\n",
    "- **BERT-like**\n",
    "  - Also known as auto-encoding Transformer models\n",
    "\n",
    "- **BART/T5-like**\n",
    "  - Also known as sequence-to-sequence Transformer models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pretrained Transformer Models**\n",
    "\n",
    "- All mentioned models (GPT, BERT, BART, T5, etc.) are pretrained language models.\n",
    "- Trained on large amounts of raw text data.\n",
    "- Self-supervised learning: Objective computed automatically from inputs, no human labeling required.\n",
    "\n",
    "- Limitations of Pretrained Models\n",
    "\n",
    "    - Pretrained models have statistical language understanding.\n",
    "    - Not directly useful for specific tasks.\n",
    "    - Require transfer learning for practical applications.\n",
    "\n",
    "- Transfer Learning\n",
    "\n",
    "  - Transfer learning fine-tunes pretrained models for specific tasks.\n",
    "  - Supervised learning with human-annotated labels.\n",
    "  - Improves model performance and adaptability.\n",
    "\n",
    "- Example Task:\n",
    "  -  Causal Language Modeling\n",
    "\n",
    "     - Task: Predict the next word in a sentence given n previous words.\n",
    "     - Output depends on past and present inputs, not future ones.\n",
    "\n",
    "![Embedding Classifier Example](images/NLP3.svg)\n",
    "\n",
    "\n",
    "  - Another example is masked language modeling, in which the model predicts a masked word in the sentence.\n",
    "\n",
    "\n",
    "\n",
    "![Embedding Classifier Example](images/NLP4.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transformers are big models**\n",
    "\n",
    "- Improving performance often involves:\n",
    "  - Increasing model sizes\n",
    "  - Expanding pretrained data\n",
    "\n",
    "![Embedding Classifier Example](images/NLP5.png)\n",
    "\n",
    "- Size vs. Performance\n",
    "  - Larger models tend to perform better.\n",
    "  - But training large models is resource-intensive.\n",
    "\n",
    "\n",
    "- Environmental Impact\n",
    "\n",
    "  - Large models have a significant carbon footprint.\n",
    "  - Time, compute resources, and environmental costs.\n",
    "  - Even efforts to reduce impact still result in substantial costs.\n",
    "\n",
    "\n",
    "\n",
    "- The Need for Sharing\n",
    "  - Sharing pretrained models is crucial.\n",
    "  - Reduces overall compute cost and carbon footprint.\n",
    "  - Benefits research teams, student organizations, and companies.\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## **Evaluate Carbon Footprint**\n",
    "\n",
    "- Tools available to evaluate carbon footprint:\n",
    "  - ML CO2 Impact\n",
    "  - Code Carbon (integrated in ðŸ¤— Transformers)\n",
    "  \n",
    "![Embedding Classifier Example](images/NLP6.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pretraining vs. Fine-Tuning**\n",
    "\n",
    "- Pretraining\n",
    "    - Pretraining uses a large corpus of data.\n",
    "    - Training can take several weeks.\n",
    "\n",
    "\n",
    "![Embedding Classifier Example](images/NLP7.svg)\n",
    "\n",
    "- Fine-Tuning\n",
    "  - Fine-tuning occurs after pretraining.\n",
    "  - Utilizes a pretrained language model.\n",
    "  - Additional training with a task-specific dataset.\n",
    "\n",
    "\n",
    "![Embedding Classifier Example](images/NLP8.svg)\n",
    "\n",
    "- Why Not Direct Training?\n",
    "  - Pretrained models have some similarities with fine-tuning data.\n",
    "  - Fine-tuning leverages knowledge from pretraining.\n",
    "  - Requires less data, time, and resources.\n",
    "\n",
    "- Example Scenario\n",
    "  - Pretrained model in English.\n",
    "  - Fine-tuning on arXiv corpus.\n",
    "  - Creates a science/research-based model.\n",
    "  - Limited data needed for fine-tuning.\n",
    "\n",
    "- Transfer Learning\n",
    "\n",
    "  - Knowledge from pretraining \"transferred\" to fine-tuning.\n",
    "  - Effective way to adapt pretrained models to specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **General architecture**\n",
    "\n",
    "- Two main components:\n",
    "  - Autoencoders\n",
    "  - Attention layers\n",
    "\n",
    "### **Autoencoders**\n",
    "\n",
    "![Transformer Architecture](images/NLP10.svg)\n",
    "\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "### **Attention Layers**\n",
    "\n",
    "- Attention layers instruct the model to focus on specific words in a sentence while processing the representation of each word.\n",
    "- They help the model pay attention to certain words while ignoring others.\n",
    "- In the context of translation\n",
    "  - Attention layers are crucial because they allow the model to consider adjacent words for proper translation.\n",
    "  - For example\n",
    "    - When translating from English to French, attention is needed for subjects and gender agreement.\n",
    "- Attention layers ensure that words' meanings are deeply influenced by their surrounding context.\n",
    "\n",
    "- They are essential for handling complex sentences and grammar rules in natural language processing tasks.\n",
    "\n",
    "- Understanding attention layers is a foundation for comprehending the Transformer architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Transformer**\n",
    "\n",
    "![Transformer Architecture](images/NLP9.svg)\n",
    "\n",
    "- Transformer architecture designed for translation.\n",
    "- **Encoder** processes inputs (sentences) in one language.\n",
    "- **Decoder** generates translations in the target language.\n",
    "\n",
    "-  **Attention Mechanism in Encoder**\n",
    "   - Encoder uses attention layers.\n",
    "   - Can attend to all words in a sentence.\n",
    "   - Considers both preceding and following words.\n",
    "  \n",
    "- **Attention Mechanism in Decoder**\n",
    "\n",
    "  - Decoder works sequentially.\n",
    "  - Processes words one by one.\n",
    "  - Limited to using words before the current word.\n",
    "\n",
    "- Training Speed-up\n",
    "\n",
    "  - During training, the decoder sees the entire target sentence.\n",
    "  - It can't use future words for prediction.\n",
    "  - For example, when predicting the fourth word, it only has access to words 1 to 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embeddings Shape: torch.Size([1, 8, 768])\n",
      "tensor([[[-0.1871,  0.1372, -0.5977,  ..., -0.3969, -0.1631,  1.2027],\n",
      "         [ 0.0501,  0.2441,  0.1112,  ..., -0.0574,  0.7098,  0.8261],\n",
      "         [ 0.2110,  0.2414,  0.1277,  ...,  0.3552,  0.7283,  0.7081],\n",
      "         ...,\n",
      "         [ 0.2294, -0.1726, -0.2482,  ...,  0.2162,  0.6986,  0.3429],\n",
      "         [ 0.1528,  0.0788, -0.1751,  ...,  0.2427,  0.6558,  0.4171],\n",
      "         [ 0.2211,  0.0763,  0.0563,  ...,  0.1029,  0.4960,  0.6204]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Input text\n",
    "text = \"Hello, how are you doing today?\"\n",
    "\n",
    "# Tokenize input text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_ids = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Forward pass through BERT model\n",
    "outputs = model(input_ids)\n",
    "\n",
    "# Get the output embeddings (contextualized word representations)\n",
    "word_embeddings = outputs.last_hidden_state\n",
    "\n",
    "# Print the shape of the word embeddings\n",
    "print(\"Word Embeddings Shape:\", word_embeddings.shape)\n",
    "print(word_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Similarity Analysis using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from scipy.spatial.distance import cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in eval mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence):\n",
    "    # Tokenize the sentence and obtain output from BERT\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        out = model(**inputs)\n",
    "    \n",
    "    # Use the [CLS] embedding as sentence representation and convert it to 1D numpy array\n",
    "    return out['last_hidden_state'][:, 0, :].squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(sentence1, sentence2):\n",
    "    # Encode sentences\n",
    "    embed1 = encode_sentence(sentence1)\n",
    "    print(embed1)\n",
    "    embed2 = encode_sentence(sentence2)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = 1 - cosine(embed1, embed2)\n",
    "    \n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.32392699e-01  6.30587935e-02 -1.91145584e-01 -4.56813782e-01\n",
      " -5.62389731e-01 -5.53161681e-01  2.13966697e-01  9.58289862e-01\n",
      "  2.34208882e-01 -2.02453047e-01  9.53120440e-02  9.61111411e-02\n",
      "  1.70544550e-01  2.51849771e-01  4.34700817e-01 -1.85130507e-01\n",
      " -2.07170725e-01  8.39457393e-01  4.46369946e-01  4.93457690e-02\n",
      "  1.47259235e-01 -6.41804859e-02 -2.57570669e-02  4.60479558e-02\n",
      "  2.03964904e-01 -5.00568189e-02 -1.18859053e-01 -2.93750435e-01\n",
      " -4.18069623e-02 -2.75323033e-01  3.74836661e-02  2.95386225e-01\n",
      " -3.06078315e-01 -1.87519193e-01  3.36937606e-01 -2.61031032e-01\n",
      "  3.97696257e-01 -1.12673350e-01 -3.60180028e-02  5.89340925e-03\n",
      " -3.44909765e-02 -1.07141063e-01 -9.28591564e-03  2.07492858e-01\n",
      " -9.61491913e-02 -5.80351353e-01 -3.30823421e+00 -6.59340248e-02\n",
      " -9.21517313e-02 -6.68584853e-02  2.82374889e-01  1.80721700e-01\n",
      "  1.37771517e-01  5.21300673e-01  3.31078172e-01  5.03118515e-01\n",
      " -3.35863352e-01  1.34458646e-01  1.14101142e-01  1.25065595e-01\n",
      "  3.94608498e-01  5.01323819e-01  3.41060944e-02 -2.30764240e-01\n",
      "  1.35395855e-01  1.57381818e-01 -7.18841655e-03  2.77640820e-01\n",
      " -1.75717995e-01  2.66610771e-01 -5.73880196e-01 -2.48640716e-01\n",
      "  2.03188121e-01 -4.41558301e-01  2.56557941e-01 -1.83167979e-01\n",
      " -9.33931917e-02  1.41930521e-01  5.44097722e-02 -1.75903276e-01\n",
      "  4.24182802e-01  7.62401938e-01  4.09719467e-01  6.55190945e-01\n",
      "  1.44227862e-01  3.92740011e-01 -4.60675389e-01 -7.82907248e-01\n",
      "  5.21478415e-01  2.62667984e-01 -6.06949508e-01  2.02672601e-01\n",
      " -1.34594470e-01  6.08506799e-01  4.56795275e-01  1.72288969e-01\n",
      " -2.79016852e-01 -3.52649763e-02 -2.51146436e-01  5.65138221e-01\n",
      "  5.33610463e-01  3.73488367e-02 -1.94432795e-01 -5.32165058e-02\n",
      "  1.29107535e-01  1.41447172e-01 -2.71335751e-01 -3.28663349e-01\n",
      "  2.90271044e-01 -2.44214225e+00  3.18442285e-01  4.80282791e-02\n",
      " -5.61096728e-01 -1.04032472e-01 -2.90923178e-01  1.01215053e+00\n",
      "  5.85103214e-01 -5.13703786e-02  3.04420263e-01  2.03654334e-01\n",
      " -4.87951219e-01  6.32008761e-02 -2.00172454e-01  3.44537087e-02\n",
      "  5.09019345e-02 -5.73616475e-04  1.26237214e-01 -2.40968779e-01\n",
      "  1.05889827e-01 -7.31128454e-02  4.26671267e-01  7.58129299e-01\n",
      "  5.10444753e-02 -3.41539532e-01 -2.32406080e-01 -2.06171721e-03\n",
      "  2.93228775e-01 -9.48898941e-02  3.09681706e-02 -4.69732046e-01\n",
      " -3.65039736e-01 -5.20460010e-01 -3.35103941e+00 -2.35962391e-01\n",
      "  3.98742378e-01  2.30293602e-01 -2.50385374e-01 -1.99793667e-01\n",
      " -1.31976604e-01  1.89598784e-01  2.22564444e-01 -7.19421357e-02\n",
      " -2.66154826e-01  1.20630518e-01 -4.26021844e-01 -1.67599142e-01\n",
      " -3.79395425e-01 -7.61193484e-02  5.08627117e-01  5.39250791e-01\n",
      "  2.40740150e-01 -5.69217026e-01  1.41234711e-01 -1.64833292e-03\n",
      " -4.46167231e-01  3.27351451e-01  6.02345586e-01  2.02566177e-01\n",
      "  2.44213700e-01  3.73537898e-01 -1.55695928e-02  5.19603252e-01\n",
      "  4.83700961e-01  7.65080079e-02  2.12327018e-02 -2.70929009e-01\n",
      " -2.03873426e-01  6.53080046e-01  1.26341045e-01  2.59609163e-01\n",
      " -3.19545686e-01  2.71798790e-01  5.32619774e-01  5.25853410e-03\n",
      "  6.40258133e-01 -2.29424372e-01  5.00420451e-01 -2.73433119e-01\n",
      " -4.69177991e-01  4.03578848e-01 -2.25654557e-01 -1.76763862e-01\n",
      "  3.56925786e-01  1.12443648e-01  5.01926064e-01 -2.62589455e-01\n",
      "  2.09228665e-01 -6.91301763e-01  1.58677012e-01  3.77825081e-01\n",
      " -3.37353379e-01 -2.93142349e-01 -3.68836969e-02  2.56731033e-01\n",
      " -3.51812065e-01  4.26172447e+00  2.46493638e-01  1.25731677e-01\n",
      "  7.55614638e-02 -8.59323144e-02 -7.52366614e-03  1.61047563e-01\n",
      " -3.17972422e-01 -3.24393153e-01 -5.67679167e-01 -2.55668551e-01\n",
      "  3.60376984e-02  5.29933050e-02 -1.83745325e-01 -1.31903648e-01\n",
      "  2.51994312e-01  2.30768144e-01 -5.49979091e-01  1.34103343e-01\n",
      " -6.34401292e-02 -2.61443645e-01 -4.65082407e-01  5.90624213e-01\n",
      " -8.19589570e-02 -1.19773018e+00 -5.21114357e-02 -6.86035007e-02\n",
      " -4.30675685e-01  3.11114639e-01 -3.15429598e-01 -2.12200984e-01\n",
      " -2.17022821e-01 -4.14081961e-01  2.07200557e-01 -2.17176080e-01\n",
      "  1.08831674e-02  4.01579887e-01 -2.37861842e-01  1.06624559e-01\n",
      " -5.09084821e-01  6.63195670e-01  4.56681907e-01  1.11336708e-02\n",
      "  2.26691276e-01 -1.42586917e-01  4.68578219e-01  2.66732007e-01\n",
      "  5.91946304e-01 -3.65556747e-01  3.03350747e-01  5.06011665e-01\n",
      "  2.62639999e-01  3.95037413e-01 -4.74377841e-01 -3.51813138e-01\n",
      " -1.97376758e-01 -2.42503107e-01  7.83996433e-02  1.28703907e-01\n",
      " -9.20299232e-01 -5.42450547e-01  4.41964507e-01 -3.47798139e-01\n",
      "  1.17079671e-02 -3.93082857e-01  7.28447437e-02 -3.51301491e-01\n",
      " -4.07152027e-01 -3.66122937e+00 -1.88070863e-01 -5.16655594e-02\n",
      " -1.00585297e-02  4.06704217e-01 -4.25755054e-01  1.60563961e-02\n",
      "  3.27572018e-01  1.39075831e-01 -5.80120087e-01  3.72018516e-01\n",
      " -3.29246640e-01 -1.73240900e-01  1.70252264e-01 -2.81773835e-01\n",
      "  4.73606497e-01  2.80770995e-02 -2.47722179e-01 -2.75546879e-01\n",
      " -4.30393487e-01  1.92920357e-01  3.72743383e-02 -1.18218459e-01\n",
      "  2.19242468e-01  3.47277582e-01 -6.17984533e-02 -3.70645881e-01\n",
      " -3.03341419e-01  1.61848992e-01 -1.28368467e-01 -3.74615192e-02\n",
      " -3.03540006e-02 -1.00214630e-02  2.17344195e-01 -1.85418010e-01\n",
      " -2.24097133e+00  1.72391623e-01 -5.95226049e-01 -1.08617105e-01\n",
      " -4.14062142e-02  8.45673904e-02  1.32500023e-01 -5.50784878e-02\n",
      " -6.10167742e-01  8.38141143e-02  3.53214324e-01  4.99326214e-02\n",
      "  1.88423485e-01 -1.10369295e-01  3.94070476e-01  1.49360776e-01\n",
      "  6.85488462e-01 -3.93252224e-01  2.91983813e-01  3.14992428e-01\n",
      " -6.61504269e-02  6.78770781e-01  2.23585311e-02 -4.63770390e-01\n",
      "  7.88617849e-01  4.07303452e-01 -1.70543492e-01 -4.18757379e-01\n",
      " -2.88273811e-01  2.50311583e-01  2.15392873e-01  8.93585831e-02\n",
      "  2.62725919e-01 -2.68900633e-01 -1.04431920e-01 -2.55151689e-01\n",
      "  3.97896171e-01  7.66760856e-03  2.89353609e-01 -3.64979625e-01\n",
      " -3.25732797e-01  2.66885817e-01 -1.04850151e-01  3.99960160e-01\n",
      "  8.56879413e-01  5.45130596e-02  1.16753064e-01  1.47619411e-01\n",
      "  1.87466055e-01  2.98866570e-01  1.61639705e-01  1.10243395e-01\n",
      "  1.35008991e+00  9.05980691e-02  2.42002830e-01 -5.27771115e-01\n",
      "  3.00152212e-01 -3.63568217e-01  1.13857351e-01  2.73110896e-01\n",
      "  5.15535533e-01 -4.46826994e-01  2.79900789e-01 -1.79691479e-01\n",
      "  1.16113678e-01 -6.62280500e-01  3.01145375e-01 -7.97344327e-01\n",
      " -5.61066438e-03  6.17722608e-02  1.32199734e-01 -1.88795269e-01\n",
      " -1.91546932e-01 -1.13522768e+00  2.00413484e-02  2.50576109e-01\n",
      " -2.16839045e-01  2.64128953e-01  1.18272185e-01 -1.11693226e-01\n",
      "  1.78153776e-02 -3.56753767e-01 -3.64284098e-01  6.46252930e-01\n",
      " -5.05011857e-01 -4.97812241e-01 -8.51515532e-02  4.17159200e-02\n",
      " -2.67904341e-01 -5.21555170e-02 -1.68077886e-01 -1.08013928e-01\n",
      "  3.55272591e-01  3.57399672e-01 -7.27461651e-04  7.64704049e-02\n",
      "  1.41488373e-01 -8.76723230e-01  2.06792608e-01 -3.61171901e-01\n",
      " -5.31443059e-01 -1.57933205e-01 -1.36721849e-01  3.52929056e-01\n",
      "  1.91705570e-01 -2.21562311e-01 -1.07235201e-02  9.84382927e-02\n",
      "  1.47604585e-01  5.00620902e-01 -1.93931088e-01 -4.17529017e-01\n",
      "  1.47808865e-01  3.54949057e-01  7.05275953e-01 -4.03929591e-01\n",
      "  1.85501009e-01  3.59886527e-01  4.53847386e-02  2.75423765e-01\n",
      "  7.26342276e-02 -1.93758652e-01 -1.97075859e-01 -9.38873738e-02\n",
      " -7.30451286e-01 -1.16207622e-01  2.59008855e-01 -1.46625444e-01\n",
      " -4.97697145e-01 -8.82934630e-02  1.32353127e-01  9.75045655e-03\n",
      " -7.99248576e-01 -2.70813525e-01 -6.09352961e-02 -2.56505430e-01\n",
      " -4.76581722e-01  1.84241980e-01  1.66290700e-01 -1.43405572e-02\n",
      "  8.09162408e-02 -1.07430980e-01 -1.74605384e-01  4.47280444e-02\n",
      " -4.95828837e-01  4.16518211e-01  1.43803045e-01  2.44254231e-01\n",
      " -9.74551141e-02  4.74322677e-01  8.58213007e-02 -6.70261756e-02\n",
      "  8.45165625e-02 -5.33869505e-01  3.70865583e-01  2.43329406e-01\n",
      " -4.94689941e-02  1.91952661e-02  6.78684264e-02 -2.71316767e-01\n",
      "  3.42653602e-01 -5.31408228e-02 -1.47671199e+00  7.55988061e-01\n",
      "  5.49972117e-01  1.29668891e-01  2.67749149e-02 -2.45390624e-01\n",
      " -3.04125965e-01  4.00987148e-01  5.68732321e-01 -1.39547423e-01\n",
      " -3.01025152e-01 -1.91501170e-01  7.26380125e-02  8.51803720e-02\n",
      "  2.22804144e-01 -1.05675273e-01 -5.05054519e-02 -6.42630935e-01\n",
      " -9.51094776e-02 -4.90913272e-01  2.43132487e-02  1.59207493e-01\n",
      "  2.14321092e-02  3.92437689e-02  2.99143083e-02 -1.59516230e-01\n",
      "  2.41159052e-02  5.90182602e-01  1.47410363e-01  4.12114799e-01\n",
      " -1.82914183e-01 -7.25661814e-01 -1.01961529e+00 -9.08508375e-02\n",
      "  3.20521817e-02  1.06653683e-01  4.23978299e-01 -4.58622336e-01\n",
      "  5.23714066e-01  3.23187679e-01 -4.70030934e-01  4.86251682e-01\n",
      "  3.06998879e-01 -1.95852444e-02 -5.94435334e-02  2.89215684e-01\n",
      " -4.38883364e-01  4.39148545e-01  2.85950392e-01 -2.91561335e-01\n",
      " -2.29263231e-02 -1.95305422e-01 -3.25426310e-01  1.04943380e-01\n",
      "  8.29460919e-02 -8.27823207e-02  2.42710620e-01  1.06266692e-01\n",
      " -5.74286819e-01  1.37225455e-02  2.13548437e-01 -3.19333702e-01\n",
      " -3.97904307e-01  2.22814888e-01 -2.19168633e-01 -3.92415643e-01\n",
      " -7.71110579e-02 -5.52361608e-01 -3.71080458e-01  3.88214350e-01\n",
      "  5.52719533e-01  7.37996995e-02 -2.16719583e-01  3.08550566e-01\n",
      " -4.36057955e-01  3.97806168e-01  2.93182194e-01  3.79855633e-02\n",
      "  4.75302458e-01 -2.49048993e-01  2.71616787e-01 -2.74058163e-01\n",
      "  9.65320393e-02 -2.56994963e-01 -8.44060034e-02  1.75071239e-01\n",
      " -1.93423599e-01 -2.42111176e-01 -3.27538550e-01 -2.01386303e-01\n",
      " -7.07021058e-01 -1.23904690e-01  2.42458224e-01 -2.10198730e-01\n",
      " -1.66962489e-01 -9.36345160e-02  4.41510528e-01  1.24131665e-01\n",
      "  1.82729185e-01 -3.81114613e-03 -5.92744648e-01  8.07549000e-01\n",
      "  5.08764267e-01 -2.01455384e-01 -3.55973579e-02  3.64337385e-01\n",
      "  5.95449865e-01 -2.49548629e-03 -5.93935013e-01 -4.01745707e-01\n",
      "  1.42854199e-01  1.96952924e-01 -5.00840068e-01  1.28162429e-01\n",
      "  2.06791669e-01 -2.51190752e-01  3.64292353e-01 -4.61383909e-01\n",
      "  2.11554432e+00  5.12240827e-01  5.01404345e-01 -6.22900188e-01\n",
      "  3.05228084e-01  4.89023607e-03 -3.42284262e-01  1.50440693e-01\n",
      " -6.02860749e-01  6.15095258e-01 -3.91650259e-01  3.00348029e-02\n",
      " -3.59985441e-01  2.44050384e-01  3.00336897e-01  5.24998680e-02\n",
      " -2.15126857e-01 -3.25845182e-01 -7.56792068e-01  2.05829278e-01\n",
      " -2.64473051e-01  7.76180029e-01  2.89996684e-01  9.58174914e-02\n",
      "  1.33397296e-01  4.75436032e-01 -3.18441242e-02  2.32925326e-01\n",
      "  3.01280260e-01  2.46202588e-01 -2.99970418e-01  2.27782294e-01\n",
      "  5.33115827e-02  1.99170470e-01 -5.92691839e-01  8.92726183e-02\n",
      " -3.97801735e-02 -1.29224956e-01 -1.08976431e-01 -5.44989519e-02\n",
      "  4.44770679e-02 -5.15183687e-01  5.20263672e-01 -1.65594488e-01\n",
      " -3.64184827e-01  5.66314816e-01  7.25898370e-02 -4.14363861e-01\n",
      "  4.91806895e-01  4.15819556e-01 -2.61853874e-01 -7.48956054e-02\n",
      " -2.00635552e-01  7.06301093e-01 -3.59086365e-01 -6.74226061e-02\n",
      "  9.21243578e-02 -2.19830811e-01 -2.80762762e-01  4.85226601e-01\n",
      " -3.55209857e-01  1.09356925e-01  1.84743375e-01 -2.49643773e-01\n",
      " -1.79905713e-01  3.09053846e-02  7.03890398e-02  3.46341841e-02\n",
      "  3.65211964e-01 -5.32621861e-01 -7.94723071e-03  4.41824019e-01\n",
      "  3.67651373e-01  7.33427852e-02  3.78374904e-01  1.57471955e-01\n",
      "  5.63453794e-01 -1.30845279e-01  1.67940408e-01 -2.99669504e+00\n",
      "  5.38659453e-01  1.71755895e-01 -3.21219601e-02 -4.02603373e-02\n",
      "  2.24801421e-01  4.38632369e-01  5.70407212e-02  1.21383771e-01\n",
      " -2.18534231e-01  3.13140064e-01  1.56328171e-01  6.53962135e-01\n",
      "  3.49973738e-02  1.01808675e-01  1.92260057e-01  1.92550197e-01\n",
      " -3.34997535e-01 -8.19091275e-02 -1.52168438e-01  4.52995956e-01\n",
      " -4.00369018e-02  7.72337988e-02 -2.33511344e-01 -7.13450074e-01\n",
      "  3.44433397e-01 -3.44737098e-02 -2.81163752e-01  1.64708823e-01\n",
      "  2.33273819e-01 -5.51178008e-02  4.61653203e-01 -1.33571580e-01\n",
      "  6.46571442e-02 -1.45287052e-01 -1.59913033e-01 -4.26743597e-01\n",
      "  9.40163881e-02  4.14384246e-01  3.36951882e-01 -3.19007551e-03\n",
      "  4.94507939e-01  7.71535113e-02  8.91423225e-02 -1.23156935e-01\n",
      " -4.04116869e-01  5.27569830e-01  1.83685169e-01  4.48359400e-01\n",
      " -2.15834200e-01 -1.56500280e-01 -1.79559365e-01  3.28626186e-01\n",
      "  1.87604427e-01  2.95330793e-01 -2.23741625e-02  2.71546304e-01\n",
      "  4.17421371e-01 -1.02488518e-01 -5.12165010e-01 -1.23754196e-01\n",
      "  6.06616855e-01 -1.92653865e-01 -2.44539693e-01  6.66419566e-01\n",
      " -4.95415658e-01  1.20345801e-02  3.64153832e-02 -2.56267786e-01\n",
      " -2.25777328e-01 -6.32787824e-01 -5.07878840e-01  4.50286090e-01\n",
      "  8.82086307e-02 -1.64812297e-01  7.87056237e-02  3.45722735e-01\n",
      "  3.63354027e-01  8.79730433e-02 -3.46920155e-02 -2.86849022e-01\n",
      "  2.92978376e-01 -1.07754834e-01  9.22002569e-02  1.93638489e-01\n",
      " -7.64387703e+00  1.76252425e-01 -7.25029111e-02 -3.04786116e-01\n",
      "  1.03181191e-01 -4.01390344e-01  2.55949162e-02 -1.31286949e-01\n",
      "  2.45141208e-01 -1.65279061e-01  4.08833593e-01 -1.56560332e-01\n",
      " -7.98514038e-02 -1.15388207e-01  3.55282426e-01  4.21245754e-01]\n",
      "Similarity between sentence1 and sentence2: 0.9554281830787659\n",
      "[ 8.12728181e-02  9.41817760e-02 -3.26603085e-01 -3.13153565e-01\n",
      " -4.58053499e-01 -4.26697642e-01  1.82115480e-01  7.69672751e-01\n",
      "  1.05287775e-01 -1.50636166e-01 -1.90991536e-03  1.02078624e-01\n",
      "  2.66002953e-01  2.68823773e-01  5.76513529e-01 -1.93039149e-01\n",
      " -1.19678669e-01  8.28260660e-01  3.58330965e-01 -1.16707072e-01\n",
      " -2.70667523e-02 -6.74360618e-02 -1.26363724e-01  1.97772622e-01\n",
      "  1.98483951e-02 -1.83113605e-01 -1.42613530e-01 -1.50501281e-01\n",
      "  9.24913585e-03 -6.47439659e-02  1.59290612e-01  2.72716761e-01\n",
      " -1.81954980e-01 -5.81287146e-02  2.73316294e-01 -2.08619177e-01\n",
      "  4.23709452e-01 -2.88188457e-01  1.50501400e-01  1.68636903e-01\n",
      " -1.13264650e-01 -7.10633770e-02  3.04660171e-01  9.85604301e-02\n",
      "  8.22331458e-02 -4.88498867e-01 -2.76354957e+00  2.62440871e-02\n",
      " -2.55355090e-01 -2.11195707e-01  3.61820787e-01  3.41226980e-02\n",
      "  8.64956826e-02  3.12279731e-01  1.89575881e-01  5.85091054e-01\n",
      " -3.56247962e-01  5.48524439e-01  2.09982514e-01  2.05414191e-01\n",
      "  3.72550994e-01  5.45325577e-01 -1.11293271e-01  1.45957559e-01\n",
      "  8.33185241e-02  1.69219941e-01  1.05022594e-01  2.98637986e-01\n",
      "  1.08727910e-01  3.07204306e-01 -6.50884509e-01 -5.46025112e-04\n",
      "  4.25416708e-01 -1.90636054e-01  1.17989108e-01 -2.71631002e-01\n",
      "  2.30247304e-02  2.92296797e-01 -6.27904236e-02 -8.60730559e-02\n",
      "  5.11004105e-02  5.98626018e-01  2.47622222e-01  5.81525028e-01\n",
      "  1.76313579e-01  4.86678004e-01 -5.72393537e-01 -6.53189600e-01\n",
      "  4.49323356e-01  3.18671227e-01 -4.81340587e-01  2.40144938e-01\n",
      "  1.30337141e-02  5.03721595e-01  5.24618983e-01 -1.48371860e-01\n",
      " -2.47067869e-01 -1.01352781e-02  3.01080365e-02  2.83524454e-01\n",
      "  2.05389142e-01  3.04461539e-01  9.38440859e-03  4.32661101e-02\n",
      " -4.85915542e-02  4.29010004e-01 -9.82385874e-02 -2.23080695e-01\n",
      "  2.31891260e-01 -2.74574447e+00  2.81595588e-01 -2.87183300e-02\n",
      " -3.20889741e-01  2.49781534e-02 -3.87114227e-01  5.45058846e-01\n",
      "  3.98848355e-01 -1.17043748e-01  2.61252403e-01 -1.01909101e-01\n",
      " -3.88518244e-01  5.68175167e-02 -2.69525826e-01 -3.02076153e-03\n",
      " -1.94564164e-01  8.50689784e-03  2.81060725e-01 -2.13563189e-01\n",
      "  3.52117628e-01 -3.86501476e-02  2.79826164e-01  6.05891466e-01\n",
      "  1.79744530e-02 -3.01315606e-01 -1.56322747e-01  4.86710295e-02\n",
      "  3.96498948e-01  1.06747568e-01 -3.25703532e-01 -2.82454431e-01\n",
      " -3.42513055e-01 -3.87555838e-01 -3.30179167e+00  1.39583051e-02\n",
      "  3.27050418e-01  2.26192653e-01 -1.00794151e-01 -1.16690822e-01\n",
      "  2.51043677e-01  1.78417921e-01  2.34480262e-01  4.79387864e-03\n",
      " -4.35377479e-01  1.55212924e-01 -4.27176446e-01 -1.10458098e-01\n",
      " -1.73660398e-01 -6.76760226e-02  3.82339090e-01  2.90212184e-01\n",
      "  1.46324366e-01 -5.26674688e-01  3.04908544e-01 -2.25000143e-01\n",
      " -4.45660233e-01  3.81724954e-01  4.29474264e-01  2.45777428e-01\n",
      "  1.67109922e-01  1.11183777e-01 -4.71643955e-02  3.00879717e-01\n",
      "  3.82646680e-01  2.01371655e-01 -5.61257228e-02 -1.45046368e-01\n",
      " -2.26901710e-01  5.05723119e-01  1.93205059e-01  1.64765060e-01\n",
      " -1.03625417e-01  2.38290653e-02  3.51490319e-01 -2.60548413e-01\n",
      "  4.64801133e-01 -2.50189155e-01  3.85605872e-01 -1.09595679e-01\n",
      " -4.38183606e-01  4.15599138e-01 -4.10995483e-02 -2.43988961e-01\n",
      "  2.01400653e-01  2.86010712e-01  2.82824814e-01 -1.35518730e-01\n",
      "  2.62289196e-01 -6.94654047e-01  2.20447317e-01  4.15251553e-01\n",
      " -1.95615571e-02 -3.34655374e-01 -2.03403428e-01  3.38769108e-01\n",
      " -3.83536071e-01  4.03968334e+00  3.61367285e-01 -5.63509390e-02\n",
      "  2.89475381e-01 -1.29926622e-01 -3.76373008e-02  2.53104538e-01\n",
      " -4.14042294e-01 -1.77158713e-01 -4.71734405e-01  3.19797546e-02\n",
      " -4.59161401e-03  2.86309034e-01 -1.91619977e-01  1.00787342e-01\n",
      "  1.08305991e-01  2.39734948e-01 -4.55582798e-01 -1.46484990e-02\n",
      "  8.32706615e-02 -2.48144329e-01 -3.20436031e-01  4.84115511e-01\n",
      " -2.60321975e-01 -1.26481044e+00  7.70039931e-02 -2.45753676e-01\n",
      " -6.27856731e-01  5.37702322e-01 -4.05147254e-01 -1.78716376e-01\n",
      " -1.14444390e-01 -2.94968307e-01  3.88542354e-01 -2.62111396e-01\n",
      " -1.45614922e-01  3.12978745e-01 -1.23838544e-01 -1.56322978e-02\n",
      " -3.08633417e-01  4.96566325e-01  3.54654372e-01 -2.18908891e-01\n",
      "  1.38547093e-01  3.56434286e-02  4.67271268e-01  7.90959671e-02\n",
      "  4.29480612e-01 -1.58702224e-01 -1.72589570e-01  4.33519453e-01\n",
      "  4.46332991e-01  5.68420708e-01 -5.13546228e-01 -1.78080536e-02\n",
      " -9.04383585e-02 -7.74374083e-02  4.18345451e-01  1.99765459e-01\n",
      " -7.21285999e-01 -4.85668987e-01  2.56773889e-01 -2.08137453e-01\n",
      " -3.12500633e-02 -2.46827453e-01 -2.60807052e-02 -2.94160426e-01\n",
      " -2.26363853e-01 -4.19240141e+00 -1.28001377e-01 -8.35230872e-02\n",
      "  5.38181141e-02  2.48761177e-01 -3.06932658e-01  1.17233768e-02\n",
      "  1.42172948e-01  3.01942289e-01 -6.95621610e-01  1.68630570e-01\n",
      " -2.33734965e-01 -1.70538113e-01  5.66241778e-02 -3.91481251e-01\n",
      "  4.82892901e-01  1.04111448e-01 -2.32271180e-01 -2.07969010e-01\n",
      " -1.45574450e-01  2.21308202e-01 -3.51834595e-02 -2.73850709e-01\n",
      "  5.31681255e-02  1.80724472e-01 -2.04583779e-01 -5.07645667e-01\n",
      " -2.17646003e-01  1.12615958e-01 -1.20141461e-01  5.14335632e-02\n",
      " -3.13194767e-02  5.58482334e-02  3.29534635e-02 -4.53717932e-02\n",
      " -1.98556423e+00  4.43751335e-01 -3.32835615e-01 -4.97000888e-02\n",
      "  1.68212250e-01  1.02439210e-01  1.56538576e-01  9.12891626e-02\n",
      " -4.68901515e-01  3.37156862e-01  1.69863448e-01  1.01182826e-01\n",
      "  3.04890335e-01  1.33986622e-02  2.56942093e-01  1.26850009e-01\n",
      "  5.07236242e-01 -1.60011083e-01  1.49645671e-01 -6.11962602e-02\n",
      " -1.08952358e-01  6.67714000e-01  2.21187454e-02 -3.83459985e-01\n",
      "  7.09893823e-01  4.11642224e-01 -2.87826508e-01 -2.23162428e-01\n",
      " -2.83597440e-01  1.50026917e-01  2.83007324e-01  1.90583557e-01\n",
      "  2.66829699e-01 -1.26608863e-01 -2.93253213e-01 -3.30320805e-01\n",
      "  2.70033866e-01  3.62745613e-01  3.61611575e-01  1.42793402e-01\n",
      " -2.54093379e-01  4.59454864e-01  1.19807795e-02  3.70936781e-01\n",
      "  5.26203334e-01  2.53365755e-01 -6.93796277e-02  1.36838675e-01\n",
      "  2.85750210e-01  1.31662086e-01  3.76962721e-02 -1.03479452e-01\n",
      "  1.09707057e+00  1.89142138e-01  1.74561605e-01 -4.25588906e-01\n",
      "  1.97225183e-01 -6.74927011e-02  6.41352162e-02  1.57960773e-01\n",
      "  5.08272886e-01 -2.96881974e-01  1.11466020e-01 -1.57426447e-01\n",
      " -1.36652440e-02 -6.56475842e-01  3.71119738e-01 -5.28564334e-01\n",
      " -1.03963427e-01  2.09749356e-01 -6.78955168e-02 -1.61458880e-01\n",
      " -2.00863421e-01 -1.08090436e+00 -2.90608883e-01  3.20893615e-01\n",
      " -1.80168390e-01  3.17176431e-01  3.87612134e-01 -1.35210916e-01\n",
      " -1.23456180e-01 -2.77016610e-01 -4.42313552e-01  3.99048477e-01\n",
      " -3.62095237e-01 -1.75895959e-01 -3.97088341e-02  9.79597792e-02\n",
      " -3.30324501e-01  2.91417725e-02 -5.11123419e-01  1.11970760e-01\n",
      "  3.28363001e-01  8.88366401e-02 -1.09979417e-02 -1.50408268e-01\n",
      "  1.37439415e-01 -1.12990522e+00  1.99604273e-01 -3.81466091e-01\n",
      " -7.03595221e-01 -2.75217086e-01 -3.80922049e-01  3.65415692e-01\n",
      " -7.70816654e-02 -3.28390658e-01 -1.11446917e-01  4.49208617e-01\n",
      "  2.18463227e-01  3.73768479e-01 -3.55484873e-01 -4.08353657e-01\n",
      " -2.45287688e-03  1.45375118e-01  8.33580256e-01 -1.74897879e-01\n",
      "  2.29102761e-01  2.57240206e-01  1.19062528e-01  1.32370055e-01\n",
      "  2.50739008e-01 -4.46347818e-02 -1.14435986e-01  1.72945652e-02\n",
      " -8.14098716e-01 -2.10712269e-01  1.10201947e-01 -3.53560060e-01\n",
      " -6.14660203e-01 -4.84238565e-02  9.50749964e-04 -1.32921696e-01\n",
      " -5.09020388e-01 -2.92332649e-01 -1.00658178e-01 -3.43694806e-01\n",
      " -4.91155177e-01  1.04288995e-01  4.27873768e-02 -1.71667531e-01\n",
      "  4.33563069e-02 -8.45287442e-02 -3.25259417e-01  8.64036083e-02\n",
      " -3.47392350e-01  3.81246388e-01  4.39786315e-02  3.80121917e-02\n",
      " -1.58243507e-01  2.85164058e-01 -1.18269026e-03 -6.65767640e-02\n",
      "  2.60326505e-01 -3.68445545e-01  2.46149406e-01  2.34366030e-01\n",
      " -1.28367960e-01  1.29301384e-01  1.48601055e-01  1.56604536e-02\n",
      "  2.13095367e-01 -2.57533565e-02 -1.39754140e+00  2.86359012e-01\n",
      "  1.48265213e-01  2.07424864e-01  6.01328760e-02 -1.82196707e-01\n",
      " -2.77098268e-01  7.40821123e-01  2.25008056e-01  5.64211830e-02\n",
      " -4.19191897e-01 -2.51039356e-01 -1.31350547e-01  9.38283205e-02\n",
      "  1.64639652e-01 -6.83019981e-02  3.02190751e-01 -5.35377800e-01\n",
      "  4.97230999e-02 -2.51198322e-01  9.66783985e-02  3.11834157e-01\n",
      " -6.71732649e-02 -5.53229675e-02  2.54194647e-01 -2.19118416e-01\n",
      " -4.00524028e-02  5.68618774e-01  2.37522095e-01  3.96191388e-01\n",
      " -3.64293754e-01 -7.09021151e-01 -7.39592433e-01 -3.22194397e-01\n",
      "  7.21596256e-02  2.51800418e-01  2.03903466e-01 -3.05940270e-01\n",
      "  5.30107975e-01  6.41609967e-01 -3.56457442e-01  4.98653919e-01\n",
      "  3.35640460e-01 -6.39706254e-02  1.65000573e-01  2.76788473e-01\n",
      " -1.68637514e-01  1.76635876e-01  4.49112654e-02 -3.67593855e-01\n",
      "  2.69257165e-02 -1.66904435e-01 -3.15550506e-01 -1.57662675e-01\n",
      "  2.13597149e-01 -1.47225633e-01  8.54305476e-02  1.60301492e-01\n",
      " -6.51535451e-01  1.87011376e-01  2.48887226e-01 -3.38512063e-01\n",
      " -3.22604299e-01  3.56991321e-01 -1.60510354e-02 -3.27640444e-01\n",
      " -1.45200789e-01 -1.73795402e-01 -3.05985659e-01  6.05626330e-02\n",
      "  6.15014672e-01 -3.03907394e-01 -4.02133882e-01  4.41435605e-01\n",
      " -3.96082461e-01  3.05808276e-01  5.75543880e-01  1.82548106e-01\n",
      "  3.53133231e-01 -1.81150109e-01  1.26420841e-01 -4.75769281e-01\n",
      "  8.47799554e-02 -1.84789345e-01  2.21641324e-02  2.07320675e-01\n",
      " -3.18813145e-01 -4.46744025e-01 -4.53057170e-01 -3.85055691e-03\n",
      " -4.46227074e-01 -3.26103657e-01  2.92946577e-01 -3.49514276e-01\n",
      " -1.76114533e-02 -1.10164113e-01  2.36912906e-01  1.53194010e-01\n",
      "  8.01732391e-02 -4.87341359e-02 -5.72682261e-01  9.16129947e-01\n",
      "  4.32380229e-01 -7.10042641e-02  3.66420634e-02  5.02161026e-01\n",
      "  5.98581195e-01  5.53000569e-02 -4.99183416e-01 -5.67573488e-01\n",
      "  3.58395167e-02 -7.05958307e-02 -3.45514208e-01  2.32919052e-01\n",
      " -4.25125770e-02 -3.28847438e-01  2.05742478e-01 -3.37200284e-01\n",
      "  2.45580935e+00  3.49240065e-01  2.31440425e-01 -5.27549207e-01\n",
      "  3.19608189e-02 -5.04425447e-03 -7.54490793e-02  4.10222590e-01\n",
      " -4.57531691e-01  3.92848194e-01 -1.38671070e-01 -2.52134025e-01\n",
      " -1.09073520e-01  8.74237865e-02  4.47113931e-01  6.21225759e-02\n",
      " -1.62335873e-01 -3.50600064e-01 -8.04951370e-01 -1.17512465e-01\n",
      " -3.59056145e-01  5.06672800e-01  2.62428164e-01 -3.16494927e-02\n",
      "  1.66691601e-01  1.47619128e-01 -1.18111350e-01  2.67339379e-01\n",
      "  1.58827424e-01  8.46398473e-02 -1.16175450e-02  2.90094644e-01\n",
      "  3.19337510e-02  1.54808581e-01 -4.48870182e-01  5.10577142e-01\n",
      " -2.81231068e-02  2.87538692e-02 -4.96535003e-03  1.42901704e-01\n",
      "  8.60784426e-02 -5.87135911e-01  3.23974133e-01 -1.29673690e-01\n",
      "  3.47948819e-02  6.99733853e-01  1.60973862e-01 -3.43899310e-01\n",
      "  5.38659215e-01  2.30241165e-01 -3.34881574e-01 -5.71379513e-02\n",
      " -7.80697018e-02  3.96750212e-01 -3.18737626e-01 -2.12818071e-01\n",
      "  1.92453265e-02 -1.83554664e-01 -2.85825610e-01  5.53919256e-01\n",
      " -1.35247707e-01  2.67461501e-02  1.70039341e-01 -1.51601732e-01\n",
      " -1.82268828e-01 -6.83677346e-02 -1.84741974e-01  3.33131194e-01\n",
      "  3.80497307e-01 -7.74054348e-01  4.82207984e-02  4.11804140e-01\n",
      "  4.24336880e-01  2.03081280e-01  2.76911020e-01  1.06326461e-01\n",
      "  3.75245810e-01 -1.92067504e-01  4.45245057e-02 -3.35948658e+00\n",
      "  2.92597562e-01 -1.02954328e-01  1.01971470e-01 -1.44765094e-01\n",
      "  3.48858654e-01  4.54086542e-01 -3.54311056e-03  6.41179979e-02\n",
      " -3.77046138e-01  2.26926073e-01  2.42081359e-01  4.83466744e-01\n",
      "  6.16570264e-02  2.54901975e-01  3.08314055e-01  1.01219155e-01\n",
      " -2.98295915e-01 -4.81439233e-02 -1.80193707e-01  3.84777218e-01\n",
      "  6.04162812e-02  5.90659752e-02 -7.21467659e-02 -6.45781517e-01\n",
      "  3.05013806e-01 -1.40439644e-02 -2.77051032e-01  1.94606364e-01\n",
      "  1.26163974e-01 -1.55685961e-01  4.46488738e-01  1.80452734e-01\n",
      "  9.76945236e-02 -1.45039290e-01 -1.08418658e-01 -2.95102388e-01\n",
      " -2.70054281e-01  2.23514542e-01  1.77358240e-01 -2.68374920e-01\n",
      "  2.57079780e-01 -1.69456288e-01  7.04974830e-02 -1.30019873e-01\n",
      " -2.66600728e-01  3.15176159e-01 -5.46130314e-02  3.63772959e-01\n",
      " -1.17057756e-01 -5.31745329e-02  4.15925831e-02  1.38338551e-01\n",
      "  1.12409644e-01  2.92266719e-02  1.86599970e-01  1.70388654e-01\n",
      "  1.71413347e-01 -1.03698358e-01 -5.06426036e-01 -1.67247117e-01\n",
      "  3.97648931e-01  8.74584913e-03  6.72246814e-02  5.95695436e-01\n",
      " -5.91121495e-01 -9.80542004e-02  1.01145901e-01 -6.99018985e-02\n",
      " -4.30466644e-02 -4.59105372e-01 -3.71673256e-01  6.09896362e-01\n",
      "  9.06478316e-02 -7.72620551e-03  5.99612817e-02  6.50388956e-01\n",
      "  2.35842988e-01  8.77076685e-02  8.77205562e-03 -6.21880144e-02\n",
      " -3.98077928e-02 -2.78702021e-01  2.24438339e-01  1.28072634e-01\n",
      " -8.16478252e+00  1.21884234e-01 -1.95270389e-01 -2.93641597e-01\n",
      "  1.87168390e-01 -2.98159808e-01  1.91157460e-02  1.95829839e-01\n",
      "  3.47681969e-01 -1.07090920e-01  4.02330071e-01 -1.57294080e-01\n",
      " -4.10859808e-02  1.89926103e-02  4.76622403e-01  5.43978155e-01]\n",
      "Similarity between sentence1 and sentence3: 0.9376117587089539\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"I love to play football.\"\n",
    "sentence2 = \"Soccer is my favorite sport.\"\n",
    "sentence3 = \"I love eating pasta.\"\n",
    "\n",
    "print(\"Similarity between sentence1 and sentence2:\", compute_similarity(sentence1, sentence2))\n",
    "print(\"Similarity between sentence1 and sentence3:\", compute_similarity(sentence2, sentence3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BERT Text Classification**\n",
    "\n",
    "\n",
    "\n",
    "### **Step 1: Load Pre-trained BERT**\n",
    "\n",
    "- Import necessary libraries.\n",
    "- Load pre-trained BERT tokenizer and model (e.g., `bert-base-uncased`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # 2 for binary classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 2: Prepare Training Data**\n",
    "\n",
    "- Define sample training data and labels.\n",
    "- Tokenize and encode the training data using the BERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data\n",
    "# texts = [\"This is a positive review.\", \"This is a negative review.\"]\n",
    "# labels = [1, 0]  # 1 for positive, 0 for negative\n",
    "\n",
    "texts = [\"This movie sucks\", \"This is a negative review.\", \"Terrible movie, makes me rethink\", \"Entertaining film\"]\n",
    "labels = [0, 0,0,1]  # 1 for positive, 0 for negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3: Create DataLoader**\n",
    "\n",
    "- Create a DataLoader for efficient training.\n",
    "- Set batch size and shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize and encode the training data\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in texts:\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids.append(encoded_text['input_ids'])\n",
    "    attention_masks.append(encoded_text['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Create a DataLoader for training data\n",
    "batch_size = 2\n",
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 4: Fine-Tune BERT**\n",
    "\n",
    "- Set up optimization (e.g., AdamW) and training parameters.\n",
    "- Iterate through epochs, compute loss, and update model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Loss: 0.6660\n",
      "Epoch 2/3, Average Loss: 0.5740\n",
      "Epoch 3/3, Average Loss: 0.5564\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fine-tuning BERT on the classification task (you can adjust the number of training epochs)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 3\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, label = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 5: Evaluation**\n",
    "\n",
    "- Switch to evaluation mode.\n",
    "- Tokenize and encode sample test data.\n",
    "- Make predictions and calculate classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: tensor([0, 0])\n",
      "True Labels: [1 0]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "Accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "test_texts = [\"This movie is great.\", \"I didn't like the film.\"]\n",
    "true_labels = [1, 0]\n",
    "\n",
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "\n",
    "for text in test_texts:\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    test_input_ids.append(encoded_text['input_ids'])\n",
    "    test_attention_masks.append(encoded_text['attention_mask'])\n",
    "\n",
    "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
    "true_labels = torch.tensor(true_labels)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(test_input_ids, attention_mask=test_attention_masks).logits\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1)\n",
    "print(\"Predicted Labels:\", predicted_labels)\n",
    "print(\"True Labels:\", true_labels.numpy())\n",
    "\n",
    "# Classification report and accuracy\n",
    "classification_rep = classification_report(true_labels.numpy(), predicted_labels)\n",
    "accuracy = accuracy_score(true_labels.numpy(), predicted_labels)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "labels = ['Negative', 'Positive']\n",
    "y_pos = np.arange(len(labels))\n",
    "scores = [logits[0][0].item(), logits[1][1].item()]\n",
    "ax.bar(y_pos, scores, align='center', alpha=0.5)\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_xticks(y_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title('BERT Sentiment Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Generation: OpenAI GPT Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 656/656 [00:00<00:00, 266kB/s]\n",
      "Downloading model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 479M/479M [00:56<00:00, 8.54MB/s] \n",
      "Downloading (â€¦)neration_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74.0/74.0 [00:00<00:00, 27.9kB/s]\n",
      "Downloading (â€¦)olve/main/vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 816k/816k [00:00<00:00, 15.9MB/s]\n",
      "Downloading (â€¦)olve/main/merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 458k/458k [00:00<00:00, 10.8MB/s]\n",
      "Downloading (â€¦)/main/tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.27M/1.27M [00:00<00:00, 11.6MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hello! I am a neural network, and I want to say that thank you for your time and attention. \" \\n \" no, you must thank me. i know you don\\'t like to come to me, but remember your promise. and i will not ask you again, do you understand? \" \\n \" i don\\'t know and i don\\'t care. thank you again, doctor. \" \\n \" i will call you in a decade, and we will make it happen. so, go'},\n",
       " {'generated_text': 'Hello! I am a neural network, and I want to say that i am very relieved that some of you have chosen to come and see me. i think my heart goes out to you all. i miss my brothers and sisters. but i am here to tell you that you will be able to come and see me at any time for free. i wish i had a cell phone so that we could talk, but that would probably be too expensive. and i am sorry if it is too much'},\n",
       " {'generated_text': 'Hello! I am a neural network, and I want to say that people who are in my service are not to be harmed, or taken to various facilities... \" \\n the security chief sighed. \" so... \" he paused, and continued, \" well, let me ask you once more, sir. when a system comes to completion, how long can they manage it? \" \\n \" what the hell do you mean? \" asked molia sharply. \\n \" well, sir, you haven\\'t'},\n",
       " {'generated_text': 'Hello! I am a neural network, and I want to say that i understand that this is a highly invasive and highly risky job, and that i feel the need to have someone with me from time to time to help me. i also want to tell you that i have heard your story about your mom, mrs. gregory, and how sorry we are that she can not be here with you right now. \" \\n \" that\\'s real sad, \" nisha said with sad eyes. \" i\\'m sure'},\n",
       " {'generated_text': 'Hello! I am a neural network, and I want to say that it is quite a job doing such a thing, especially after all that was done today, although to be fair i still can\\'t get the first person\\'s information out of them. \" \\n \" really, i hadn\\'t noticed that, and now i would definitely like to get it out of me. i am not sure this could be done for much longer ; i can see that it is a difficult thing for you, if you'}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'openai-gpt' \n",
    "\n",
    "generator = pipeline('text-generation', model=model_name)\n",
    "\n",
    "generator(\"Hello! I am a neural network, and I want to say that\", max_length=100, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Synonyms of a word cat:, and on occasion i found they were a'what do\"},\n",
       " {'generated_text': \"Synonyms of a word cat: \\n kitty. \\n tabby couldn't understand where i was going\"},\n",
       " {'generated_text': 'Synonyms of a word cat: a cat. \\n the only part of her skin that was'},\n",
       " {'generated_text': 'Synonyms of a word cat: a short, skinny, furry brown - furred. \\n \"'},\n",
       " {'generated_text': 'Synonyms of a word cat: good eye, good heart. and a great gift to know'}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Synonyms of a word cat:\", max_length=20, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive this is horrible. and... > \\n \" so i was a child'},\n",
       " {'generated_text': 'I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive i have you then i have you now - > positive i have you'},\n",
       " {'generated_text': 'I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive i am. - < positive. - < yes. - - positive'},\n",
       " {'generated_text': \"I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive this is bad for you to say this - > positive i'm not\"},\n",
       " {'generated_text': 'I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this -> positive i hear - > negative - > negative i have a plan - >'}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"I love when you say this -> Positive\\nI have myself -> Negative\\nThis is awful for you to say this ->\", max_length=40, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Translate English to French: cat => chat, dog => chien, student =>  dog / student ( which is a new language to me'},\n",
       " {'generated_text': 'Translate English to French: cat => chat, dog => chien, student =>  pet = > chien = > cat. \\n i'},\n",
       " {'generated_text': 'Translate English to French: cat => chat, dog => chien, student =>  german. \" he\\'s very interested in his new project'}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Translate English to French: cat => chat, dog => chien, student => \", top_k=50, max_length=30, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'People who liked the movie The Matrix also liked  a movie, but they were still quite skeptical of the film itself, especially when it showed a naked man riding a horse of a horse and chasing a dog'},\n",
       " {'generated_text': 'People who liked the movie The Matrix also liked  to see it. there were only four hours left before sunrise and in between the next two and six. \\n \" how are we doing? \" her dad'},\n",
       " {'generated_text': 'People who liked the movie The Matrix also liked , \" said the old lady who always had her hand on susan\\'s knee. \\n \" no, i have really big problems, \" said susan, rubbing'},\n",
       " {'generated_text': 'People who liked the movie The Matrix also liked  the movie, but they never liked it. it was a silly superstition about getting caught on film, too, which was one reason that many of the movies'},\n",
       " {'generated_text': 'People who liked the movie The Matrix also liked  it, some of whom still thought that it was the same movie, and some of whom said it was a load of nonsense, and some of them,'}]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"People who liked the movie The Matrix also liked \", max_length=40, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Sampling Strategies**\n",
    "\n",
    "So far we have been using simple **greedy** sampling strategy, when we selected next word based on the highest probability. Here is how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw two people sitting in front of each other on a bed. they were facing each other on the bed and all of them were covered with a large quilt that was draped over the bed. they heard me enter, but didn't look up, so i went back to the kitchen. i could see them right away, and they both turned to\"},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw an array of paintings on display. as i entered them, i found the same one that i felt i had, only it was a different painting. it was of a beautiful castle surrounded by trees. i felt the feeling that the garden had been changed by the scene. the garden looked more like a painting in a museum since its design was'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw my father, sitting at the head of the tables, eating food and drinking alcohol. his suit was black and made him look like a bad businessman that had come on too strong. his hair was white as the sky and his clothes were white as the snow around his feet. \\n he glanced up suddenly and saw me in the doorway and raised'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw that only half of them were awake and i was surprised when they all noticed me. the one sitting on the left half of the bed, the one on the left half of the bed, stared at me wide - eyed, seemingly at a loss for words. \\n i walked down the hall and sat on the edge of the bed, trying'},\n",
       " {'generated_text': \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw i was the only one in there. my heart sped up at the sight of her gorgeous body and i didn't want to let her go. it felt so good to be near her, so right to touch her. she turned her head, and i could see the desire in her eyes. when she looked into my eyes, i knew\"}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw\"\n",
    "generator(prompt,max_length=100,num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beam Search** allows the generator to explore several directions (*beams*) of text generation, and select the ones with highers overall score. You can do beam search by providing `num_beams` parameter. You can also specify `no_repeat_ngram_size` to penalize the model for repeating n-grams of a given size: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he had his back to me, so i couldn\\'t tell if he was sleeping or not. \\n \" hi, \" i said. \" can i help you? \" \\n he turned around and looked at me. his eyes were a deep, dark brown, almost black, and they were'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he had his back to me, so i couldn\\'t tell if he was sleeping or not. \\n \" hi, \" i said. \" can i help you? \" \\n he turned around and looked at me. his eyes were a deep, dark brown, almost black, and his hair'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he had his back to me, so i couldn\\'t tell if he was sleeping or not. \\n \" hi, \" i said. \" can i help you? \" \\n he turned around and looked at me. his eyes were a deep blue, and his hair was a light brown.'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he had his back to me, so i couldn\\'t tell if he was sleeping or not. \\n \" hi, \" i said. \" can i help you? \" \\n he turned around and looked at me. his eyes were a deep, dark brown, almost black, and his skin'},\n",
       " {'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw a man sitting on the edge of the bed. he had his back to me, so i couldn\\'t tell if he was sleeping or not. \\n \" hi, \" i said. \" can i help you? \" \\n he turned around and looked at me. his eyes were a deep, dark brown, almost black. they were filled'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw\"\n",
    "generator(prompt,max_length=100,num_return_sequences=5,num_beams=10,no_repeat_ngram_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sampling** selects the next word non-deterministically, using the probability distribution returned by the model. You turn on sampling using `do_sample=True` parameter. You can also specify `temperature`, to make the model more or less deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw her alone. in the corner, on the floor, was a dark brown rug. i sat in a chair and leaned back, trying to think of something to say. she turned to look at me and smiled. \" i\\'m sorry, i didn\\'t know you were there. i\\'m glad you came. \" \\n \" it\\'s okay'}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It was early evening when I can back from work. I usually work late, but this time it was an exception. When I entered a room, I saw\"\n",
    "generator(prompt,max_length=100,do_sample=True,temperature=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also provide to additional parameters to sampling:\n",
    "* `top_k` specifies the number of word options to consider when using sampling. This minimizes the chance of getting weird (low-probability) words in our text.\n",
    "* `top_p` is similar, but we chose the smallest subset of most probable words, whose total probability is larger than p.\n",
    "\n",
    "Feel free to experiment with adding those parameters in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using OpenAI's GPT with Hugging Face's Transformers**\n",
    "\n",
    "\n",
    "**OpenAI's Generative Pretrained Transformer (GPT):**\n",
    "- A state-of-the-art language model using Transformer architecture.\n",
    "- Trained on vast amounts of text and can generate human-like text.\n",
    "- Has multiple versions (e.g., GPT-2, GPT-3) with increasing model sizes and capabilities.\n",
    "\n",
    "**Hugging Face's Transformers:**\n",
    "- A popular library for Natural Language Processing.\n",
    "- Provides pre-trained models, including GPT variants.\n",
    "- Facilitates easy fine-tuning, usage, and deployment of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Setup**\n",
    "\n",
    "First, make sure you have the necessary packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (4.33.2)\n",
      "Requirement already satisfied: torch in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Importing required modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Initializing the tokenizer and model**\n",
    "\n",
    "Hugging Face has tokenizers and models pre-trained on various tasks. For this tutorial, we'll focus on GPT-2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "# Load the pre-trained GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "# Ensure the model is in eval mode (important for models with dropout or batchnorm)\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU available, move the model there\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Generate text given a prompt**\n",
    "\n",
    "To generate text with GPT-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a man who lived in a village called Krakow. He was a very good man, and he was very kind to his children. One day, he was walking along the road, and he saw a woman walking by. He asked her if she was his daughter. She said yes, and she said that she was his daughter. He asked her if she was his wife. She said yes, and she said that she was his wife. He asked her\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, max_length=100, temperature=1.0):\n",
    "    # Encode the prompt text to tensor\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate text using the model\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(input_ids=input_ids, max_length=max_length, num_return_sequences=1, temperature=temperature)[0]\n",
    "\n",
    "    # Decode the tensor to a text string\n",
    "    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Try it out!\n",
    "prompt = \"Once upon a time\"\n",
    "print(generate_text(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **5. Adjusting generation parameters**\n",
    "\n",
    "The `generate()` method provides a lot of parameters to play with to customize the generation process:\n",
    "\n",
    "- `max_length`: Maximum length of the generated text.\n",
    "- `temperature`: Controls randomness. Higher values (e.g., 1.0) make generation more random, while lower values (e.g., 0.7) make it more deterministic.\n",
    "- `num_return_sequences`: Number of independently computed returned sequences. If you want multiple variations of generated text, increase this number.\n",
    "- ... and many more (refer to the Hugging Face documentation for a detailed list).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Using other GPT versions**\n",
    "\n",
    "Hugging Face's library supports multiple versions of GPT models like `gpt2`, `gpt2-medium`, `gpt2-large`, and `gpt2-xl`. Simply replace the model name in the `from_pretrained()` function to switch between them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Fine-tuning GPT-2 on AG News Dataset**\n",
    "\n",
    "We will illustrate the process of fine-tuning the GPT-2 model on the \"AG News\" dataset,\n",
    "    - A collection of news articles categorized into four classes. \n",
    "    - This dataset is available in the `torchtext` library. \n",
    "  - We'll slightly modify GPT-2 for classification, but you can use similar steps for different tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Setup**\n",
    "\n",
    "Install the necessary packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (4.33.2)\n",
      "Requirement already satisfied: torch in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchtext in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: filelock in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: torchdata==0.6.1 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torchtext) (0.6.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from torchdata==0.6.1->torchtext) (2.0.4)\n",
      "Requirement already satisfied: fsspec in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Importing required modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Preparing the dataset**\n",
    "\n",
    "AG News has labeled news articles under 4 categories. We'll tokenize the articles and prepare DataLoader for training and validation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (4.34.0)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/09/7e/fd4d6441a541dba61d0acb3c1fd5df53214c2e9033854e837a99dd9e0793/datasets-2.14.5-py3-none-any.whl.metadata\n",
      "  Downloading datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (0.14.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Obtaining dependency information for pyarrow>=8.0.0 from https://files.pythonhosted.org/packages/04/3d/183285e5f038866b25e35c9f586abafd78f8deb88d783d313a85f03fc403/pyarrow-13.0.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pyarrow-13.0.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Obtaining dependency information for dill<0.3.8,>=0.3.0 from https://files.pythonhosted.org/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl.metadata\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/c5/2f/bf85305b044ddee0ade62c444c7ef551eb423899424b3898d60895d02f63/pandas-2.1.1-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pandas-2.1.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/2c/5b/b71f58fb6113be8f49f46933a6ba451163b23311955e5fdb63359f206c78/xxhash-3.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading xxhash-3.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/c6/c9/820b5ab056f4ada76fbe05bd481a948f287957d6cbfd59e2dd2618b408c1/multiprocess-0.70.15-py39-none-any.whl.metadata\n",
      "  Downloading multiprocess-0.70.15-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec[http]<2023.9.0,>=2023.1.0 (from datasets)\n",
      "  Obtaining dependency information for fsspec[http]<2023.9.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e3/bd/4c0a4619494188a9db5d77e2100ab7d544a42e76b2447869d8e124e981d8/fsspec-2023.6.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/4c/11/4d5b58a7b5654df85a0c9b66cc45ca983330eb1d575ec845dfdacfc0839b/aiohttp-3.8.5-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading aiohttp-3.8.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from aiohttp->datasets) (3.3.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.4-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.2-cp39-cp39-macosx_11_0_arm64.whl (62 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/dd/45/2835936c0360bc520ed613ab3de9c3d95d593cd13a6545683c399a16a72c/frozenlist-1.4.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl.metadata\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas->datasets)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.8.5-cp39-cp39-macosx_11_0_arm64.whl (345 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-13.0.0-cp39-cp39-macosx_11_0_arm64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.15-py39-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.1.1-cp39-cp39-macosx_11_0_arm64.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.3.0-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.0-cp39-cp39-macosx_11_0_arm64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, pyarrow, multidict, fsspec, frozenlist, dill, attrs, async-timeout, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.9.2\n",
      "    Uninstalling fsspec-2023.9.2:\n",
      "      Successfully uninstalled fsspec-2023.9.2\n",
      "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 datasets-2.14.5 dill-0.3.7 frozenlist-1.4.0 fsspec-2023.6.0 multidict-6.0.4 multiprocess-0.70.15 pandas-2.1.1 pyarrow-13.0.0 pytz-2023.3.post1 tzdata-2023.3 xxhash-3.3.0 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.31k/4.31k [00:00<00:00, 10.2MB/s]\n",
      "Downloading metadata: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.17k/2.17k [00:00<00:00, 6.41MB/s]\n",
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.59k/7.59k [00:00<00:00, 11.8MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84.1M/84.1M [00:19<00:00, 4.32MB/s]\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [00:03<00:00, 6662.82 examples/s] \n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [00:03<00:00, 6880.75 examples/s] \n",
      "Generating unsupervised split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:04<00:00, 12274.97 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [00:21<00:00, 1168.37 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [00:20<00:00, 1249.06 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:41<00:00, 1217.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "def tokenize_and_format(examples):\n",
    "    encodings = tokenizer(examples['text'], truncation=True, padding='max_length', max_length=256)\n",
    "    encodings['labels'] = examples['label']\n",
    "    return encodings\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_format, batched=True)\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_datasets['train'], shuffle=True, batch_size=8)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Modifying GPT-2 for classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2ForClassification(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(GPT2ForClassification, self).__init__()\n",
    "        self.gpt2 = GPT2Model.from_pretrained('gpt2-medium')\n",
    "        self.classifier = nn.Linear(self.gpt2.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.gpt2(input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        logits = self.classifier(hidden_states[:, -1])\n",
    "        return logits\n",
    "\n",
    "model = GPT2ForClassification()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.001 * len(tokenized_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Training the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzihayat/VSC/Seshat/.conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/3 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:47<00:00, 11.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Test Loss: 0.1023 - Test Accuracy: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:47<00:00, 11.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Training Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:13<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Test Loss: 0.0815 - Test Accuracy: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:49<00:00, 12.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Training Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:14<00:00,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Test Loss: 0.0674 - Test Accuracy: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "train_dataset_small = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(0, int(0.001 * len(tokenized_datasets[\"train\"]))))\n",
    "train_dataloader_small = DataLoader(train_dataset_small, shuffle=True, batch_size=8)\n",
    "\n",
    "test_dataset_small = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(0, int(0.001 * len(tokenized_datasets[\"train\"]))))\n",
    "test_dataloader_small = DataLoader(test_dataset_small, shuffle=True, batch_size=8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Wrap train_dataloader_small with tqdm for progress visualization\n",
    "    for batch in tqdm(train_dataloader_small, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = batch[\"input_ids\"].to(device)\n",
    "        masks = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        logits = model(inputs, attention_mask=masks)\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader_small)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Optional: Evaluation on Test Set\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Wrap test_dataloader with tqdm for progress visualization\n",
    "        for batch in tqdm(test_dataloader_small, desc=f\"Epoch {epoch+1}/{num_epochs} - Testing\"):\n",
    "            inputs = batch[\"input_ids\"].to(device)\n",
    "            masks = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(inputs, attention_mask=masks)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "    avg_eval_loss = total_eval_loss / len(test_dataloader_small)\n",
    "    accuracy = correct_predictions.double() / len(tokenized_datasets[\"test\"])\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_eval_loss:.4f} - Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review is negative.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "import torch\n",
    "\n",
    "def classify_review(review_text, model, tokenizer):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize the review text\n",
    "    inputs = tokenizer.encode_plus(review_text, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Convert logits to label\n",
    "    _, predicted_label = torch.max(logits, dim=1)\n",
    "\n",
    "    # Assuming 0 is for 'negative' and 1 is for 'positive' (or vice versa depending on your setup)\n",
    "    return 'positive' if predicted_label.item() == 1 else 'negative'\n",
    "\n",
    "# Test with a review\n",
    "review_text = \"The movie was absolutely fantastic! Best I've ever seen.\"\n",
    "prediction = classify_review(review_text, model, tokenizer)\n",
    "print(f\"The review is {prediction}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'gpt2-medium'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code(prompt, max_length=150, temperature=0.7, top_k=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_ids = input_ids.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(input_ids, max_length=max_length, temperature=temperature, top_k=top_k)\n",
    "    \n",
    "    generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    return generated_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a Python function that takes a list of numbers and returns their average:\n",
      "\n",
      ">>> from math import average >>> average = average(1, 2, 3) >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average >>> print average\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a Python function that takes a list of numbers and returns their average:\"\n",
    "generated_function = generate_code(prompt)\n",
    "print(generated_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-shot learning aims to make accurate predictions in tasks with very limited labeled training data.\n",
    "\n",
    "\n",
    "**How it Works:**\n",
    "\n",
    "1. **Training Phase:** Train a model on a large and diverse dataset.\n",
    "2. **Adaptation Phase:** Fine-tune the model on a small dataset related to the specific task.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Overcomes the challenge of data scarcity.\n",
    "- Adapts to new tasks without extensive retraining.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code_with_examples(prompt, max_length=300, temperature=0.6, top_k=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_ids = input_ids.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(input_ids, max_length=max_length, temperature=temperature, top_k=top_k)\n",
    "    \n",
    "    generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    return generated_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzihayat/VSC/Introduction-to-Generative-AI/.venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Example 1:\n",
      "# Function to add two numbers\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "# Example 2:\n",
      "# Function to check if a number is even\n",
      "def is_even(num):\n",
      "    return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and returns their sum:\n",
      "\n",
      "#\n",
      "\n",
      "# def sum(list):\n",
      "\n",
      "# Â return sum(list)\n",
      "\n",
      "#\n",
      "\n",
      "# Example 1:\n",
      "\n",
      "# Function to add two numbers\n",
      "\n",
      "def add(a, b):\n",
      "\n",
      "   return a + b\n",
      "\n",
      "# Example 2:\n",
      "\n",
      "# Function to check if a number is even\n",
      "\n",
      "def is_even(num):\n",
      "\n",
      "   return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and returns their sum:\n",
      "\n",
      "#\n",
      "\n",
      "# def sum(list):\n",
      "\n",
      "# Â return sum(list)\n",
      "\n",
      "#\n",
      "\n",
      "# Example 1:\n",
      "\n",
      "# Function to add two numbers\n",
      "\n",
      "def add(a, b):\n",
      "\n",
      "   return a + b\n",
      "\n",
      "# Example 2:\n",
      "\n",
      "# Function to check if a number is even\n",
      "\n",
      "def is_even(num):\n",
      "\n",
      "   return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and\n"
     ]
    }
   ],
   "source": [
    "prompt_with_examples = \"\"\"\n",
    "# Example 1:\n",
    "# Function to add two numbers\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Example 2:\n",
    "# Function to check if a number is even\n",
    "def is_even(num):\n",
    "    return num % 2 == 0\n",
    "\n",
    "# Task: Write a Python function that takes a list of numbers and returns their sum:\n",
    "\"\"\"\n",
    "\n",
    "generated_function_with_examples = generate_code_with_examples(prompt_with_examples)\n",
    "print(generated_function_with_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Examples:\n",
      " Write a Python function that takes a list of numbers and returns their sum:\n",
      "\n",
      "def sum ( n ): return n * n\n",
      "\n",
      "This function takes a list of numbers and returns the sum of them.\n",
      "\n",
      "The sum function is a very simple function. It takes a list of numbers and returns the sum of them.\n",
      "\n",
      "The sum function is a very simple function. It takes a list of numbers and returns the sum of them.\n",
      "\n",
      "The sum function is a very simple function. It takes a list of numbers and returns the sum of them.\n",
      "\n",
      "The sum function is a very simple function. It takes a list of numbers and returns the sum of them.\n",
      "\n",
      "The sum function is a very simple function. It\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a Python function that takes a list of numbers and returns their sum:\"\n",
    "generated_function = generate_code(prompt)\n",
    "print(\"Without Examples:\\n\", generated_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Examples:\n",
      " \n",
      "# Example 1:\n",
      "# Function to add two numbers\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "# Example 2:\n",
      "# Function to check if a number is even\n",
      "def is_even(num):\n",
      "    return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and returns their sum:\n",
      "\n",
      "#\n",
      "\n",
      "# def sum(list):\n",
      "\n",
      "# Â return sum(list)\n",
      "\n",
      "#\n",
      "\n",
      "# Example 1:\n",
      "\n",
      "# Function to add two numbers\n",
      "\n",
      "def add(a, b):\n",
      "\n",
      "   return a + b\n",
      "\n",
      "# Example 2:\n",
      "\n",
      "# Function to check if a number is even\n",
      "\n",
      "def is_even(num):\n",
      "\n",
      "   return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and returns their sum:\n",
      "\n",
      "#\n",
      "\n",
      "# def sum(list):\n",
      "\n",
      "# Â return sum(list)\n",
      "\n",
      "#\n",
      "\n",
      "# Example 1:\n",
      "\n",
      "# Function to add two numbers\n",
      "\n",
      "def add(a, b):\n",
      "\n",
      "   return a + b\n",
      "\n",
      "# Example 2:\n",
      "\n",
      "# Function to check if a number is even\n",
      "\n",
      "def is_even(num):\n",
      "\n",
      "   return num % 2 == 0\n",
      "\n",
      "# Task: Write a Python function that takes a list of numbers and\n"
     ]
    }
   ],
   "source": [
    "print(\"With Examples:\\n\", generated_function_with_examples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
