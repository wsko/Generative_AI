{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **A Small Project: Text Classification with DBpedia Dataset**\n",
    "### **Description:**\n",
    "In this project, you will be working with the DBpedia ontology dataset. The task is to classify textual descriptions into one of 14 classes such as \"Company\", \"Artist\", \"Athlete\", and so forth. This classification problem will allow you to apply and solidify your understanding of NLP and machine learning concepts in a hands-on manner.\n",
    "\n",
    "### **Objective:**\n",
    "- Understand and process a real-world dataset.\n",
    "- Implement a text classification model using the GPT-2 architecture.\n",
    "- Evaluate the performance of your model and aim to achieve the highest accuracy possible.\n",
    "\n",
    "### **Tasks:**\n",
    "\n",
    "#### **1. Dataset Exploration** \n",
    "- Load the `dbpedia_14` dataset.\n",
    "- Analyze the dataset: understand the distribution of labels, the length of textual descriptions, etc.\n",
    "- Split the dataset into training and test sets.\n",
    "```python\n",
    "# Import necessary libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Task 1: Dataset Exploration\n",
    "# Load the dbpedia_14 dataset\n",
    "dataset = load_dataset('dbpedia_14')\n",
    "\n",
    "# Quick exploration\n",
    "print(dataset['train'].shape)\n",
    "print(dataset['train'].features)\n",
    "print(dataset['train'][0])\n",
    "```\n",
    "#### **2. Data Pre-processing** \n",
    "- Tokenize the textual descriptions.\n",
    "- Ensure that your data is in the appropriate format for model training (e.g., tensors).\n",
    "\n",
    "#### **3. Model Building** \n",
    "- Define a classification model using the GPT-2 architecture.\n",
    "- Implement the forward pass.\n",
    "- Choose an appropriate loss function for multi-class classification.\n",
    "\n",
    "#### **4. Model Training**\n",
    "- Implement a training loop.\n",
    "- Make sure to track the loss over time. This will help you understand if your model is learning.\n",
    "- If time permits, play around with hyperparameters to see if you can get better results.\n",
    "\n",
    "#### **5. Model Evaluation**\n",
    "- Evaluate your model on the test dataset.\n",
    "- Compute classification metrics such as accuracy, F1 score, etc.\n",
    "- (Optional) Analyze cases where your model fails. What can you infer from these mistakes?\n",
    "\n",
    "#### **6. Discussion** \n",
    "- Share your results with the class.\n",
    "- Reflect on what you've learned: challenges faced, insights gained, and potential improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
